{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunset-samoa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saving-region",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import mindspore\n",
    "import numpy as np\n",
    "import mindspore.nn as nn\n",
    "import mindspore.ops.operations as P\n",
    "import mindspore.ops.functional as F\n",
    "from mindspore import Tensor\n",
    "import matplotlib.pyplot as plt\n",
    "from mindspore import Parameter\n",
    "from layers import Dense, Embedding, Conv1d\n",
    "# S: Symbol that shows starting of decoding input\n",
    "# E: Symbol that shows starting of decoding output\n",
    "# P: Symbol that will fill in blank sequence if current batch data size is short than time steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "burning-dining",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batch(sentences, src_vocab, tgt_vocab):\n",
    "    input_batch = [[src_vocab[n] for n in sentences[0].split()]]\n",
    "    output_batch = [[tgt_vocab[n] for n in sentences[1].split()]]\n",
    "    target_batch = [[tgt_vocab[n] for n in sentences[2].split()]]\n",
    "    return Tensor(input_batch, mindspore.int32), Tensor(output_batch, mindspore.int32), Tensor(target_batch, mindspore.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resistant-giant",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sinusoid_encoding_table(n_position, d_model):\n",
    "    def cal_angle(position, hid_idx):\n",
    "        return position / np.power(10000, 2 * (hid_idx // 2) / d_model)\n",
    "    def get_posi_angle_vec(position):\n",
    "        return [cal_angle(position, hid_j) for hid_j in range(d_model)]\n",
    "\n",
    "    sinusoid_table = np.array([get_posi_angle_vec(pos_i) for pos_i in range(n_position)])\n",
    "    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])  # dim 2i\n",
    "    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])  # dim 2i+1\n",
    "    return Tensor(sinusoid_table, mindspore.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confirmed-console",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attn_pad_mask(seq_q, seq_k):\n",
    "    batch_size, len_q = seq_q.shape\n",
    "    batch_size, len_k = seq_k.shape\n",
    "    \n",
    "    pad_attn_mask = P.Equal()(seq_k, 0)\n",
    "    pad_attn_mask = P.ExpandDims()(pad_attn_mask, 1) # batch_size x 1 x len_k(=len_q), one is masking\n",
    "    pad_attn_mask = P.Cast()(pad_attn_mask, mindspore.float32)\n",
    "    return P.BroadcastTo((batch_size, len_q, len_k))(pad_attn_mask) # batch_size x len_q x len_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parallel-magic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attn_subsequent_mask(subsequent_mask):\n",
    "    subsequent_mask = P.ExpandDims()(subsequent_mask, 0)\n",
    "    subsequent_mask = P.Cast()(subsequent_mask, mindspore.byte)\n",
    "    return subsequent_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quality-bride",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedFill(nn.Cell):\n",
    "    def __init__(self, value):\n",
    "        super().__init__()\n",
    "        self.value = Tensor([value], mindspore.float32)\n",
    "        self.minusend = Tensor([1.0], mindspore.float32)\n",
    "        self.sub = P.Sub()\n",
    "        self.mul = P.Mul()\n",
    "        \n",
    "    def construct(self, inputs:Tensor, mask:Tensor):\n",
    "        masked = self.sub(self.minusend, mask)\n",
    "        adder = self.mul(mask, self.value)\n",
    "        inputs = self.mul(masked, inputs)\n",
    "        output = inputs + adder\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capable-target",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaledDotProductAttention(nn.Cell):\n",
    "    def __init__(self, d_k):\n",
    "        super().__init__()\n",
    "        self.scale = Tensor(d_k, mindspore.float32)\n",
    "        self.matmul = nn.MatMul()\n",
    "        self.transpose = P.Transpose()\n",
    "        self.softmax = nn.Softmax(axis=-1)\n",
    "        self.sqrt = P.Sqrt()\n",
    "        self.masked_fill = MaskedFill(-1e9)\n",
    "        \n",
    "    def construct(self, Q, K, V, attn_mask):\n",
    "        K = self.transpose(K, (0, 1, 3, 2))\n",
    "        scores = self.matmul(Q, K) / self.sqrt(self.scale) # scores : [batch_size x n_heads x len_q(=len_k) x len_k(=len_q)]\n",
    "        scores = self.masked_fill(scores, attn_mask) # Fills elements of self tensor with value where mask is one.\n",
    "        attn = self.softmax(scores)\n",
    "        context = self.matmul(attn, V)\n",
    "        return context, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interim-selection",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Cell):\n",
    "    def __init__(self, d_model, d_k, n_heads):\n",
    "        super().__init__()\n",
    "        self.d_k = d_k\n",
    "        self.n_heads = n_heads\n",
    "        self.W_Q = Dense(d_model, d_k * n_heads)\n",
    "        self.W_K = Dense(d_model, d_k * n_heads)\n",
    "        self.W_V = Dense(d_model, d_k * n_heads)\n",
    "        self.linear = Dense(n_heads * d_k, d_model)\n",
    "        self.layer_norm = nn.LayerNorm((d_model, ), epsilon=1e-5)\n",
    "        self.attention = ScaledDotProductAttention(d_k)\n",
    "        # ops\n",
    "        self.transpose = P.Transpose()\n",
    "        self.expanddims = P.ExpandDims()\n",
    "        self.tile = P.Tile()\n",
    "        \n",
    "    def construct(self, Q, K, V, attn_mask):\n",
    "        # q: [batch_size x len_q x d_model], k: [batch_size x len_k x d_model], v: [batch_size x len_k x d_model]\n",
    "        residual, batch_size = Q, Q.shape[0]\n",
    "        q_s = self.W_Q(Q).view((batch_size, -1, self.n_heads, self.d_k)) \n",
    "        k_s = self.W_K(K).view((batch_size, -1, self.n_heads, self.d_k)) \n",
    "        v_s = self.W_V(V).view((batch_size, -1, self.n_heads, self.d_k)) \n",
    "        # (B, S, D) -proj-> (B, S, D) -split-> (B, S, H, W) -trans-> (B, H, S, W)\n",
    "        q_s = self.transpose(q_s, (0, 2, 1, 3)) # q_s: [batch_size x n_heads x len_q x d_k]\n",
    "        k_s = self.transpose(k_s, (0, 2, 1, 3)) # k_s: [batch_size x n_heads x len_k x d_k]\n",
    "        v_s = self.transpose(v_s, (0, 2, 1, 3)) # v_s: [batch_size x n_heads x len_k x d_v]\n",
    "\n",
    "        attn_mask = self.expanddims(attn_mask, 1)\n",
    "        attn_mask = self.tile(attn_mask, (1, self.n_heads, 1, 1)) # attn_mask : [batch_size x n_heads x len_q x len_k]\n",
    "        \n",
    "        # context: [batch_size x n_heads x len_q x d_v], attn: [batch_size x n_heads x len_q(=len_k) x len_k(=len_q)]\n",
    "        context, attn = self.attention(q_s, k_s, v_s, attn_mask)\n",
    "        context = self.transpose(context, (0, 2, 1, 3)).view((batch_size, -1, self.n_heads * self.d_k)) # context: [batch_size x len_q x n_heads * d_v]\n",
    "        output = self.linear(context) \n",
    "        return self.layer_norm(output + residual), attn # output: [batch_size x len_q x d_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "official-fetish",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoswiseFeedForward(nn.Cell):\n",
    "    def __init__(self, d_ff, d_model):\n",
    "        super().__init__()\n",
    "        self.conv1 = Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1)\n",
    "        self.conv2 = Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1)\n",
    "        self.layer_norm = nn.LayerNorm((d_model, ), epsilon=1e-5)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.transpose = P.Transpose()\n",
    "        \n",
    "    def construct(self, inputs):\n",
    "        residual = P.Cast()(inputs, mindspore.float32) # inputs : [batch_size, len_q, d_model]\n",
    "        output = self.transpose(inputs, (0, 2, 1))\n",
    "        output = self.conv1(output)\n",
    "        output = self.relu(output)\n",
    "        output = self.conv2(output)\n",
    "        output = self.transpose(output, (0, 2, 1))\n",
    "        return self.layer_norm(output + residual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incredible-packet",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Cell):\n",
    "    def __init__(self, d_model, d_k, n_heads, d_ff):\n",
    "        super().__init__()\n",
    "        self.enc_self_attn = MultiHeadAttention(d_model, d_k, n_heads)\n",
    "        self.pos_ffn = PoswiseFeedForward(d_ff, d_model)\n",
    "        \n",
    "    def construct(self, enc_inputs, enc_self_attn_mask):\n",
    "        enc_outputs, attn = self.enc_self_attn(enc_inputs, enc_inputs, enc_inputs, enc_self_attn_mask) # enc_inputs to same Q,K,V\n",
    "        enc_outputs = self.pos_ffn(enc_outputs) # enc_outputs: [batch_size x len_q x d_model]\n",
    "        return enc_outputs, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greater-samba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Cell):\n",
    "    def __init__(self, d_model, d_k, n_heads, d_ff):\n",
    "        super().__init__()\n",
    "        self.dec_self_attn = MultiHeadAttention(d_model, d_k, n_heads)\n",
    "        self.dec_enc_attn = MultiHeadAttention(d_model, d_k, n_heads)\n",
    "        self.pos_ffn = PoswiseFeedForward(d_ff, d_model)\n",
    "        \n",
    "    def construct(self, dec_inputs, enc_outputs, dec_self_attn_mask, dec_enc_attn_mask):\n",
    "        dec_outputs, dec_self_attn = self.dec_self_attn(dec_inputs, dec_inputs, dec_inputs, dec_self_attn_mask)\n",
    "        dec_outputs, dec_enc_attn = self.dec_enc_attn(dec_outputs, enc_outputs, enc_outputs, dec_enc_attn_mask)\n",
    "        dec_outputs = self.pos_ffn(dec_outputs)\n",
    "        return dec_outputs, dec_self_attn, dec_enc_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atmospheric-armstrong",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Cell):\n",
    "    def __init__(self, src_vocab_size, d_model, d_k, n_heads, d_ff, n_layers, src_len):\n",
    "        super().__init__()\n",
    "        self.src_emb = Embedding(src_vocab_size, d_model)\n",
    "        self.pos_emb = Embedding.from_pretrained_embedding(get_sinusoid_encoding_table(src_len+1, d_model), freeze=True)\n",
    "        self.layers = nn.CellList([EncoderLayer(d_model, d_k, n_heads, d_ff) for _ in range(n_layers)])\n",
    "        # temp positional indexes\n",
    "        self.pos = Tensor([[1, 2, 3, 4, 0]])\n",
    "        \n",
    "    def construct(self, enc_inputs):\n",
    "        # enc_inputs : [batch_size x source_len]\n",
    "        enc_outputs = self.src_emb(enc_inputs) + self.pos_emb(self.pos)\n",
    "        enc_self_attn_mask = get_attn_pad_mask(enc_inputs, enc_inputs)\n",
    "        enc_self_attns = []\n",
    "        for layer in self.layers:\n",
    "            enc_outputs, enc_self_attn = layer(enc_outputs, enc_self_attn_mask)\n",
    "            enc_self_attns.append(enc_self_attn)\n",
    "        return enc_outputs, enc_self_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seeing-germany",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Cell):\n",
    "    def __init__(self, tgt_vocab_size, d_model, d_k, n_heads, d_ff, n_layers, tgt_len):\n",
    "        super().__init__()\n",
    "        self.tgt_emb = Embedding(tgt_vocab_size, d_model)\n",
    "        self.pos_emb = Embedding.from_pretrained_embedding(get_sinusoid_encoding_table(tgt_len+1, d_model), freeze=True)\n",
    "        self.layers = nn.CellList([DecoderLayer(d_model, d_k, n_heads, d_ff) for _ in range(n_layers)])\n",
    "        \n",
    "        # temp positional indexes\n",
    "        self.pos = Tensor([[5, 1, 2, 3, 4]])\n",
    "        \n",
    "        ones = np.ones(shape=(tgt_len, tgt_len))\n",
    "        self.subsequent_mask = Tensor(np.triu(ones, k=1), dtype=mindspore.float32)\n",
    "        \n",
    "    def construct(self, dec_inputs, enc_inputs, enc_outputs):\n",
    "        # dec_inputs : [batch_size x target_len]\n",
    "        dec_outputs = self.tgt_emb(dec_inputs) + self.pos_emb(self.pos)\n",
    "        dec_self_attn_pad_mask = get_attn_pad_mask(dec_inputs, dec_inputs)\n",
    "        dec_self_attn_subsequent_mask = get_attn_subsequent_mask(self.subsequent_mask)\n",
    "        dec_self_attn_mask = P.Greater()((dec_self_attn_pad_mask + dec_self_attn_subsequent_mask), 0)\n",
    "        \n",
    "        dec_self_attn_mask = P.Cast()(dec_self_attn_mask, mindspore.float32)\n",
    "        dec_enc_attn_mask = get_attn_pad_mask(dec_inputs, enc_inputs)\n",
    "        \n",
    "        dec_self_attns, dec_enc_attns = [], []\n",
    "        for layer in self.layers:\n",
    "            dec_outputs, dec_self_attn, dec_enc_attn = layer(dec_outputs, enc_outputs, dec_self_attn_mask, dec_enc_attn_mask)\n",
    "            dec_self_attns.append(dec_self_attn)\n",
    "            dec_enc_attns.append(dec_enc_attn)\n",
    "        return dec_outputs, dec_self_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "presidential-bailey",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Cell):\n",
    "    def __init__(self, d_model, d_k, n_heads, d_ff, n_layers, src_vocab_size, tgt_vocab_size, src_len, tgt_len):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.encoder = Encoder(src_vocab_size, d_model, d_k, n_heads, d_ff, n_layers, src_len)\n",
    "        self.decoder = Decoder(tgt_vocab_size, d_model, d_k, n_heads, d_ff, n_layers, tgt_len)\n",
    "        self.projection = Dense(d_model, tgt_vocab_size, has_bias=False)\n",
    "    def construct(self, enc_inputs, dec_inputs):\n",
    "        enc_outputs, enc_self_attns = self.encoder(enc_inputs)\n",
    "        dec_outputs, dec_self_attns, dec_enc_attns = self.decoder(dec_inputs, enc_inputs, enc_outputs)\n",
    "        dec_logits = self.projection(dec_outputs) # dec_logits : [batch_size x src_vocab_size x tgt_vocab_size]\n",
    "        return dec_logits.view((-1, dec_logits.shape[-1])), enc_self_attns, dec_self_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desirable-feature",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WithLossCell(nn.Cell):\n",
    "    def __init__(self, backbone, loss_fn):\n",
    "        super(WithLossCell, self).__init__(auto_prefix=False)\n",
    "        self._backbone = backbone\n",
    "        self._loss_fn = loss_fn\n",
    "    def construct(self, *args):\n",
    "        outputs, _, _, _, = self._backbone(*args[:-1])\n",
    "        return self._loss_fn(outputs, args[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hairy-internet",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ['ich mochte ein bier P', 'S i want a beer', 'i want a beer E']\n",
    "\n",
    "# Transformer Parameters\n",
    "# Padding Should be Zero\n",
    "src_vocab = {'P': 0, 'ich': 1, 'mochte': 2, 'ein': 3, 'bier': 4}\n",
    "src_vocab_size = len(src_vocab)\n",
    "\n",
    "tgt_vocab = {'P': 0, 'i': 1, 'want': 2, 'a': 3, 'beer': 4, 'S': 5, 'E': 6}\n",
    "number_dict = {i: w for i, w in enumerate(tgt_vocab)}\n",
    "tgt_vocab_size = len(tgt_vocab)\n",
    "\n",
    "src_len = 6 # length of source\n",
    "tgt_len = 5 # length of target\n",
    "\n",
    "d_model = 512  # Embedding Size\n",
    "d_ff = 2048  # FeedForward dimension\n",
    "d_k  = 64  # dimension of K(=Q), V\n",
    "n_layers = 6  # number of Encoder of Decoder Layer\n",
    "n_heads = 8  # number of heads in Multi-Head Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pacific-pollution",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(d_model, d_k, n_heads, d_ff, n_layers, src_vocab_size, tgt_vocab_size, src_len, tgt_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "activated-ordinary",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction='mean')\n",
    "optimizer = nn.Adam(model.trainable_params(), learning_rate=0.0001)\n",
    "# print(model.trainable_params())\n",
    "enc_inputs, dec_inputs, target_batch = make_batch(sentences, src_vocab, tgt_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "human-reverse",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindspore import context\n",
    "context.set_context(mode=context.GRAPH_MODE, device_target=\"GPU\")\n",
    "\n",
    "net_with_criterion = WithLossCell(model, criterion)\n",
    "train_network = nn.TrainOneStepCell(net_with_criterion, optimizer)\n",
    "train_network.set_train()\n",
    "\n",
    "# Training\n",
    "for epoch in range(20):\n",
    "    # hidden : [num_layers * num_directions, batch, hidden_size]\n",
    "    loss = train_network(enc_inputs, dec_inputs, target_batch.view(-1))\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.6f}'.format(loss.asnumpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rubber-difficulty",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "predict, enc_self_attns, dec_self_attns, dec_enc_attns = model(enc_inputs, dec_inputs)\n",
    "predict = predict.asnumpy().argmax(1)\n",
    "print(sentences[0], '->', [number_dict[n.item()] for n in predict.squeeze()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "postal-picking",
   "metadata": {},
   "outputs": [],
   "source": [
    "def showgraph(attn):\n",
    "    attn = P.Squeeze(0)(attn[-1])[0]\n",
    "    attn = attn.asnumpy()\n",
    "    fig = plt.figure(figsize=(n_heads, n_heads)) # [n_heads, n_heads]\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attn, cmap='viridis')\n",
    "    ax.set_xticklabels(['']+sentences[0].split(), fontdict={'fontsize': 14}, rotation=90)\n",
    "    ax.set_yticklabels(['']+sentences[2].split(), fontdict={'fontsize': 14})\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dried-depth",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('first head of last state enc_self_attns')\n",
    "showgraph(enc_self_attns)\n",
    "\n",
    "print('first head of last state dec_self_attns')\n",
    "showgraph(dec_self_attns)\n",
    "\n",
    "print('first head of last state dec_enc_attns')\n",
    "showgraph(dec_enc_attns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optimum-pharmaceutical",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
